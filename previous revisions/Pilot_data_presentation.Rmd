---
title: "Online masked priming"
subtitle: "Can we get the same quality data as in a laboratory study?"
author: "Bernhard Angele, Pablo Gomez, & Manuel Perea"
institute: "Bournemouth/Valencia/San Bernardino/The Internet"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(sp)
library(leaflet)
library(lmerTest)
library(tidyverse)
library(cowplot)
library(stargazer)
source("RainCloudPlots.R")
```


# Doing research during a pandemic

- No eye-tracking!
- But lots of bored people sitting at home
- What are language-related paradigms that we can do remotely?
  - Surveys (not terribly interesting for many language researchers)
  - Self-paced reading
  - RSVP
  - Lexical decision tasks

---

# Is priming possible online?

- Overt priming certainly is
- But masked priming relies on very precise timing of the stimuli.
- Ken Forster did it a long time ago with GIFs:

  - 40 ms prime duration: 
  ![40 ms prime](http://www.u.arizona.edu/~kforster/priming/mp_demo_1.gif)
  - 100 ms prime duration: 
  ![100 ms prime](http://www.u.arizona.edu/~kforster/priming/mp_demo_2.gif)
  
- But a demo on a website and an online experiment are two very different things!

---

# Using the three Ps (Psychopy, Pavlovia, and Prolific) to collect data

- Psychopy is an experiment presentation software allowing precise display of stimuli
  - It's written in Python, but there is now the option of translating the experiments into Javascript (PsychoJS) for online presentation.
  - Pavlovia is a paid service that integrates with Psychopy and hosts the experiment code and the collected data
  - Prolific is a participant recruitment service (like Mechanical Turk, but more research-focused and less US-centric)

---

# Our experiment

- Based on Gomez, Perea, & Ratcliff (2013)

- Gomez et al. used the diffusion model to fit data from masked and unmasked prime presentation and found that masked and unmasked priming affect different model parameters:
  - masked identity priming affects the $T_{er}$ parameter which represents encoding processes
  - unmasked priming affects both $T_er$ and the drift rates parameter corresponding to the quality of information
  
- If we can show that the data from an online experiment pattern with the masked priming data from Gomez et al. rather than the unmasked priming data, that demonstrates the reliability of the online masked priming paradigm.

---

Design

- Targets: 240 words and 240 nonwords
- Conditions: 
  - prime duration (33 vs. 50 ms)
    - this corresponds to 2 vs. 3 refresh cycles at 60 Hz
  - prime condition: identical vs. unrelated
- 60 word/nonword stimuli per group


---

Participants

```{r participant_map, echo = FALSE, message=FALSE}

participant_data <- read_csv("participant_data.csv")
coordinates(participant_data) <- c("Location Longitude","Location Latitude")
leaflet(participant_data) %>% addMarkers(label = .$`Confirm Prolific ID`) %>% addTiles()
```

---

# Results


```{r main_code, echo = FALSE, warning=FALSE, message = FALSE}

csv_data <- fs::dir_ls(path = "./data", glob = "*.csv") %>%
  map_dfr(read_csv, .id = "source", col_type = cols(
  .default = col_character(), rt = col_double(), corr = col_integer(), TrialID = col_integer())) %>% 
  filter(!is.na(TrialID) & TrialID < 1000) %>%
  select(source, participant, date, OS, frameRate, rt, corr, TrialID, StimulusType, Condition, PrimeDuration, Prime, Target)

# get participants with correct responses

accuracy_by_participant <- csv_data %>% group_by(source) %>% summarise(acc = mean(corr == 1), N = n())

  
participants_to_include <- accuracy_by_participant %>% filter(N == 480 & acc > .8)   


participant_list_for_prolific <- str_extract(string = participants_to_include$source, pattern = "[a-z0-9]{24}")
paste0(participant_list_for_prolific, sep = "\n") %>% writeClipboard() # works on windows

# for now, we only have two participants with accuracy > .8 and a full data set

data_to_include <- csv_data %>% filter(source %in% participants_to_include$source) %>% mutate(StimulusType = StimulusType %>% factor, Condition = Condition %>% factor, PrimeDuration = PrimeDuration %>% factor, rt = rt * 1000)

write_csv(data_to_include, path = "current_data.csv")

data_summary_rt <- data_to_include %>% group_by(StimulusType, Condition, PrimeDuration) %>% summarise(M = mean(rt), SD = sd(rt), N = n())

# data above 1500 ms excluded

plot_raincloud(data_to_include %>% filter(corr == 1 & rt < 1500), x_column = "Condition", y_column = "rt", x_label = "Condition", y_label = "RT in ms (correct responses)", main_title = "RT by condition and word type") + 
  # put labels on the mean for easier comparison
  stat_summary(fun.data = function(x) {data.frame(label = format(mean(x), digits = 2), y = mean(x))}, 
                                      geom = "text",
                                      #width = 1,
                                      position = position_nudge(x = 0.5, y = 0),
                                      #size = 0.2,
                                      color = "black") +
  facet_grid(cols = vars(PrimeDuration), rows = vars(StimulusType), labeller = label_context)


```

---
# LMM for RT (words, correct responses)
```{r lmms}
lmm1 <- lmer(data = data_to_include %>% filter(corr == 1 & StimulusType == "WORD" & rt < 1500), rt ~ Condition * PrimeDuration + (Condition+PrimeDuration|source) + (PrimeDuration|Target))

summary(lmm1)

```

---
# gLMM for accuracy (Words)
```{r logistic_lmm}
lmm_acc <- glmer(data = data_to_include %>% filter(corr != -1 & StimulusType == "WORD" & rt < 1500), corr ~ Condition + PrimeDuration + (1|Target), family = binomial(link = "logit"))

summary(lmm_acc)

```