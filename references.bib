@article{anwyl-irvine2020,
	title = {Gorilla in our midst: An online behavioral experiment builder},
	author = {{Anwyl-Irvine}, {Alexander L.} and {Massonnié}, {Jessica} and {Flitton}, {Adam} and {Kirkham}, {Natasha} and {Evershed}, {Jo K.}},
	year = {2020},
	month = {02},
	date = {2020-02-01},
	journal = {Behavior Research Methods},
	pages = {388--407},
	volume = {52},
	number = {1},
	doi = {10.3758/s13428-019-01237-x},
	url = {https://doi.org/10.3758/s13428-019-01237-x},
	langid = {en}
}

@inbook{rezlescu2020,
	title = {Chapter 13 - More time for science: Using Testable to create and share behavioral experiments faster, recruit better participants, and engage students in hands-on research},
	author = {{Rezlescu}, {Constantin} and {Danaila}, {Iulian} and {Miron}, {Alexandru} and {Amariei}, {Ciprian}},
	editor = {{Parkin}, {Beth Louise}},
	year = {2020},
	month = {01},
	date = {2020-01-01},
	publisher = {Elsevier},
	pages = {243--262},
	series = {Real-World Applications in Cognitive Neuroscience},
	volume = {253},
	doi = {10.1016/bs.pbr.2020.06.005},
	url = {http://www.sciencedirect.com/science/article/pii/S0079612320300807},
	note = {DOI: 10.1016/bs.pbr.2020.06.005},
	langid = {en}
}

@article{deleeuw2015,
	title = {jsPsych: A JavaScript library for creating behavioral experiments in a Web browser},
	author = {{de Leeuw}, {Joshua R.}},
	year = {2015},
	month = {03},
	date = {2015-03-01},
	journal = {Behavior Research Methods},
	pages = {1--12},
	volume = {47},
	number = {1},
	doi = {10.3758/s13428-014-0458-y},
	url = {https://doi.org/10.3758/s13428-014-0458-y},
	langid = {en}
}

@article{peirce2019,
	title = {PsychoPy2: Experiments in behavior made easy},
	author = {{Peirce}, {Jonathan} and {Gray}, {Jeremy R.} and {Simpson}, {Sol} and {MacAskill}, {Michael} and {Höchenberger}, {Richard} and {Sogo}, {Hiroyuki} and {Kastman}, {Erik} and {Lindeløv}, {Jonas Kristoffer}},
	year = {2019},
	month = {02},
	date = {2019-02-01},
	journal = {Behavior Research Methods},
	pages = {195--203},
	volume = {51},
	number = {1},
	doi = {10.3758/s13428-018-01193-y},
	url = {https://doi.org/10.3758/s13428-018-01193-y},
	langid = {en}
}

@Article{gomezDiffusionModelAccount2013,
  title = {A Diffusion Model Account of Masked versus Unmasked Priming: {{Are}} They Qualitatively Different?},
  shorttitle = {A Diffusion Model Account of Masked versus Unmasked Priming},
  author = {Pablo Gomez and Manuel Perea and Roger Ratcliff},
  year = {2013},
  volume = {39},
  pages = {1731--1740},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1277(Electronic),0096-1523(Print)},
  doi = {10.1037/a0032333},
  abstract = {In the past decades, hundreds of articles have explored the mechanisms underlying priming. Most researchers assume that masked and unmasked priming are qualitatively different. For masked priming, the effects are often assumed to reflect savings in the encoding of the target stimulus, whereas for unmasked priming, it has been suggested that the effects reflect the familiarity of the prime\textendash target compound cue. In contrast, other researchers have claimed that masked and unmasked priming reflect essentially the same core processes. In this article, we use the diffusion model (R. Ratcliff, 1978, A theory of memory retrieval, Psychological Review, Vol. 85, pp. 59\textendash 108) to account for the effects of masked and unmasked priming for identity and associatively related primes. The fits of the model led us to the following conclusion: Masked related primes give a head start to the processing of the target compared with unrelated primes, whereas unmasked priming affects primarily the quality of the lexical information. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\SEESIGQR\\Gomez et al. - 2013 - A diffusion model account of masked versus unmaske.pdf;C\:\\Users\\bernh\\Zotero\\storage\\J84RYCN7\\2013-15422-001.html},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  keywords = {Lexical Decision,Models,Priming,Reaction Time},
  number = {6},
}
@Article{forsterRepetitionPrimingFrequency1984,
  title = {Repetition Priming and Frequency Attenuation in Lexical Access},
  author = {Kenneth I. Forster and Chris Davis},
  year = {1984},
  volume = {10},
  pages = {680--698},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/0278-7393.10.4.680},
  abstract = {Six experiments investigated repetition priming and frequency attenuation in lexical access with 164 college students. Repetition priming effects in lexical decision tasks are stronger for low-frequency words than for high-frequency words. This frequency attenuation effect creates problems for frequency-ordered search models that assume a relatively stable frequency effect. It was posited that frequency attenuation is a product of the involvement of the episodic memory system in the lexical decision process. This hypothesis was supported by the demonstration of constant repetition effects for high- and low-frequency words when the priming stimulus was masked; the masking was assumed to minimize the influence of any possible episodic trace of the prime. It was further shown that long-term repetition effects were much less reliable when the S was not required to make a lexical decision response to the prime. When a response was required, the expected frequency attenuation effect was restored. It is concluded that normal repetition effects consist of 2 components: a very brief lexical effect that is independent of frequency and a long-term episodic effect that is sensitive to frequency. (32 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\ELEM9Q93\\1985-24459-001.html},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  keywords = {Cognitive Discrimination,Cues,Word Frequency,Words (Phonetic Units)},
  number = {4},
}
@Book{kinoshitaMaskedPrimingState2004,
  title = {Masked {{Priming}}: {{The State}} of the {{Art}}},
  shorttitle = {Masked {{Priming}}},
  author = {Sachiko Kinoshita and Stephen J. Lupker},
  date = {2004-06-02},
  publisher = {{Psychology Press}},
  abstract = {Masked priming has a short and somewhat controversial history. When used as a tool to study whether semantic processing can occur in the absence of conscious awareness, considerable debate followed, mainly about whether masked priming truly tapped unconscious processes. For research into other components of visual word processing, however - in particular, orthographic, phonological, and morphological - a general consensus about the evidence provided by masked priming results has emerged. This book contains thirteen original chapters in which these three components of visual word processing are examined using the masked priming procedure. The chapters showcase the advantages of masked priming as an alternative to more standard methods of studying language processing that require comparisons of matched items. Based on a recent conference, this book offers up-to-date research findings, and would be valuable to researchers and students of word recognition, psycholinguistics, or reading.},
  eprint = {VH55AgAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-1-135-43220-1},
  keywords = {Psychology / Cognitive Psychology & Cognition,Psychology / General},
  langid = {english},
  pagetotal = {217},
}
@Article{vandenbusscheMechanismsMaskedPriming2009,
  title = {Mechanisms of Masked Priming: {{A}} Meta-Analysis},
  shorttitle = {Mechanisms of Masked Priming},
  author = {Eva {Van den Bussche} and Wim {Van den Noortgate} and Bert Reynvoet},
  date = {2009},
  journaltitle = {Psychological Bulletin},
  volume = {135},
  pages = {452--477},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/a0015329},
  abstract = {The extent to which unconscious information can influence behavior has been a topic of considerable debate throughout the history of psychology. A frequently used method for studying subliminal processing is the masked priming paradigm. The authors focused on studies in which this paradigm was used. Their aim was twofold: first, to assess the magnitude of subliminal priming across the literature and to determine whether subliminal primes are processed semantically, and second, to examine potential moderators of priming effects. The authors found significant priming in their analyses, indicating that unconsciously presented information can influence behavior. Furthermore, priming was observed under circumstances in which a nonsemantic interpretation could not fully explain the effects, suggesting that subliminally presented information can be processed semantically. Nonetheless, the nonsemantic processing of primes is enhanced and priming effects are boosted when the experimental context allows the formation of automatic stimulusâ€“response mappings. This quantitative review also revealed several moderators that influence the strength of priming. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\CHZI4ESE\\Van den Bussche et al. - 2009 - Mechanisms of masked priming A meta-analysis.pdf;C\:\\Users\\bernh\\Zotero\\storage\\5Z3W32W6\\2009-05290-008.html},
  keywords = {Masking,Meta Analysis,Semantic Priming,Subliminal Stimulation},
  number = {3},
}
@Article{forsterDMDXWindowsDisplay2003,
  title = {{{DMDX}}: {{A Windows}} Display Program with Millisecond Accuracy},
  shorttitle = {{{DMDX}}},
  author = {Kenneth I. Forster and Jonathan C. Forster},
  date = {2003},
  journaltitle = {Behavior research methods, instruments, \& computers},
  volume = {35},
  pages = {116--124},
  publisher = {{Springer}},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\UJLFQFH3\\Forster and Forster - 2003 - DMDX A Windows display program with millisecond a.pdf;C\:\\Users\\bernh\\Zotero\\storage\\FI74EN4T\\BF03195503.html},
  number = {1},
}
@Book{birnbaumPsychologicalExperimentsInternet2000a,
  title = {Psychological {{Experiments}} on the {{Internet}}},
  author = {Michael H. Birnbaum and Michael O. Birnbaum},
  date = {2000-03-30},
  publisher = {{Elsevier}},
  abstract = {Until recently, most psychological research was conducted using subject samples in close proximity to the investigators--namely university undergraduates. In recent years, however, it has become possible to test people from all over the world by placing experiments on the internet. The number of people using the internet for this purpose is likely to become the main venue for subject pools in coming years. As such, learning about experiments on the internet will be of vital interest to all research psychologists. Psychological Experiments on the Internet is divided into three sections. Section I discusses the history of web experimentation, as well as the advantages, disadvantages, and validity of web-based psychological research. Section II discusses examples of web-based experiments on individual differences and cross-cultural studies. Section III provides readers with the necessary information and techniques for utilizing the internet in their own research designs. Innovative topic that will capture the imagination of many readersIncludes examples of actual web based experiments},
  eprint = {sw4NHyThFFkC},
  eprinttype = {googlebooks},
  isbn = {978-0-12-099980-4},
  keywords = {Computers / Internet / General,Psychology / Experimental Psychology,Psychology / Research & Methodology,Psychology / Social Psychology},
  langid = {english},
  pagetotal = {340},
}
@Report{paolacciRunningExperimentsAmazon2010,
  title = {Running {{Experiments}} on {{Amazon Mechanical Turk}}},
  author = {Gabriele Paolacci and Jesse Chandler and Panagiotis G. Ipeirotis},
  date = {2010-06-24},
  institution = {{Social Science Research Network}},
  location = {{Rochester, NY}},
  url = {https://papers.ssrn.com/abstract=1626226},
  urldate = {2021-01-12},
  abstract = {Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by participants recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting participants, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\395NIAR9\\papers.html},
  keywords = {Experimentation,Judgment and decision-making,Online research},
  langid = {english},
  number = {ID 1626226},
  type = {SSRN Scholarly Paper},
}
@Article{austSeriousnessChecksAre2013,
  title = {Seriousness Checks Are Useful to Improve Data Validity in Online Research},
  author = {Frederik Aust and Birk Diedenhofen and Sebastian Ullrich and Jochen Musch},
  date = {2013-06-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {45},
  pages = {527--535},
  issn = {1554-3528},
  doi = {10.3758/s13428-012-0265-2},
  url = {https://doi.org/10.3758/s13428-012-0265-2},
  urldate = {2021-01-12},
  abstract = {Nonserious answering behavior increases noise and reduces experimental power; it is therefore one of the most important threats to the validity of online research. A simple way to address the problem is to ask respondents about the seriousness of their participation and to exclude self-declared nonserious participants from analysis. To validate this approach, a survey was conducted in the week prior to the German 2009 federal election to the Bundestag. Serious participants answered a number of attitudinal and behavioral questions in a more consistent and predictively valid manner than did nonserious participants. We therefore recommend routinely employing seriousness checks in online surveys to improve data validity.},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\8I6VPP8G\\Aust et al. - 2013 - Seriousness checks are useful to improve data vali.pdf},
  langid = {english},
  number = {2},
}
@Article{witzelTestingViabilityWebDMDX2013,
  title = {Testing the Viability of {{webDMDX}} for Masked Priming Experiments},
  author = {Jeffrey Witzel and Samantha Cornelius and Naoko Witzel and Kenneth I. Forster and Jonathan C. Forster},
  date = {2013-01-01},
  journaltitle = {The Mental Lexicon},
  volume = {8},
  pages = {421--449},
  publisher = {{John Benjamins}},
  issn = {1871-1340, 1871-1375},
  doi = {10.1075/ml.8.3.07wit},
  url = {https://www.jbe-platform.com/content/journals/10.1075/ml.8.3.07wit},
  urldate = {2021-01-12},
  abstract = {The DMDX software package (Forster \&amp; Forster, 2003) is a Windows-based application that displays stimuli and records responses. Recent developments in this program have made it possible to deploy DMDX experiments over the Internet. This study evaluates the viability of the web-deployable implementation of DMDX, or webDMDX, for masked priming experiments. A lexical decision task (LDT) with masked repetition priming on high- and low-frequency words and an e/a letter detection task were conducted with both lab-based DMDX (labDMDX; Experiment 1) and webDMDX. The webDMDX experiments were run on lab computers (Experiments 2) and on different (unknown) hardware (Experiment 3). The labDMDX and webDMDX experiments yielded comparable results on the LDT. In the e/a-detection task, the only important difference observed among the tests was between the lab-based experiment (Experiment 1) and the first webDMDX experiment (Experiment 2), at the 50 ms display duration. However, after a minor change in keyword coding (Experiment 2 follow-up) and an adjustment to the millisecond-to-retrace conversion process (Experiment 3), the detection rates at all display durations were similar in both labDMDX and webDMDX. Taken together, these results indicate the utility of webDMDX for masked priming experiments as well as for other time-sensitive methodologies.},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\GZ93APB9\\Witzel et al. - 2013 - Testing the viability of webDMDX for masked primin.pdf;C\:\\Users\\bernh\\Zotero\\storage\\IAW6DYSY\\ml.8.3.html},
  langid = {english},
  number = {3},
}
@Article{reimersPresentationResponseTiming2015,
  title = {Presentation and Response Timing Accuracy in {{Adobe Flash}} and {{HTML5}}/{{JavaScript Web}} Experiments},
  author = {Stian Reimers and Neil Stewart},
  date = {2015-06-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {47},
  pages = {309--327},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0471-1},
  url = {https://doi.org/10.3758/s13428-014-0471-1},
  urldate = {2021-01-13},
  abstract = {Web-based research is becoming ubiquitous in the behavioral sciences, facilitated by convenient, readily available participant pools and relatively straightforward ways of running experiments: most recently, through the development of the HTML5 standard. Although in most studies participants give untimed responses, there is a growing interest in being able to record response times online. Existing data on the accuracy and cross-machine variability of online timing measures are limited, and generally they have compared behavioral data gathered on the Web with similar data gathered in the lab. For this article, we took a more direct approach, examining two ways of running experiments onlineâ€”Adobe Flash and HTML5 with CSS3 and JavaScriptâ€”across 19 different computer systems. We used specialist hardware to measure stimulus display durations and to generate precise response times to visual stimuli in order to assess measurement accuracy, examining effects of duration, browser, and system-to-system variability (such as across different Windows versions), as well as effects of processing power and graphics capability. We found that (a) Flash and JavaScriptâ€™s presentation and response time measurement accuracy are similar; (b) within-system variability is generally small, even in low-powered machines under high load; (c) the variability of measured response times across systems is somewhat larger; and (d) browser type and system hardware appear to have relatively small effects on measured response times. Modeling of the effects of this technical variability suggests that for most within- and between-subjects experiments, Flash and JavaScript can both be used to accurately detect differences in response times across conditions. Concerns are, however, noted about using some correlational or longitudinal designs online.},
  file = {C\:\\Users\\bernh\\Zotero\\storage\\LNWFUJ6U\\Reimers and Stewart - 2015 - Presentation and response timing accuracy in Adobe.pdf},
  langid = {english},
  number = {2},
}

@article{bridges2020,
	title = {The timing mega-study: comparing a range of experiment generators, both lab-based and online},
	author = {{Bridges}, {David} and {Pitiot}, {Alain} and {MacAskill}, {Michael R.} and {Peirce}, {Jonathan W.}},
	year = {2020},
	month = {07},
	date = {2020-07-20},
	journal = {PeerJ},
	pages = {e9414},
	volume = {8},
	doi = {10.7717/peerj.9414},
	url = {https://peerj.com/articles/9414},
	note = {Publisher: PeerJ Inc.},
	langid = {en}
}

@article{anwyl-irvine2020a,
	title = {Realistic precision and accuracy of online experiment platforms, web browsers, and devices},
	author = {{Anwyl-Irvine}, {Alexander} and {Dalmaijer}, {Edwin S.} and {Hodges}, {Nick} and {Evershed}, {Jo K.}},
	year = {2020},
	month = {11},
	date = {2020-11-02},
	journal = {Behavior Research Methods},
	doi = {10.3758/s13428-020-01501-5},
	url = {https://doi.org/10.3758/s13428-020-01501-5},
	langid = {en}
}
